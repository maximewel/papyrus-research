{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset declaration\n",
    "Custom datasets loads the BRUSH samples in memory, each signal representing a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "class BrushDataset(Dataset):\n",
    "    \"\"\"The BRUSH dataset object is used to retrieve all samples from the BRUSH dataset\n",
    "    This dataset retrives them as:\n",
    "    Sample  = Offline image\n",
    "    Label   = Online signal\n",
    "    The loading of the dataset is special, as we retrieve only the label in memory and build\n",
    "    the images at runtime.\n",
    "    \"\"\"\n",
    "    brush_root: str\n",
    "    display_stats: bool\n",
    "    save_to_file: bool\n",
    "\n",
    "    DRAW_COLOR_WHITE = 0\n",
    "    DRAW_COLOR_BLACK = 255\n",
    "    DRAW_COLOR_SIZE = 1\n",
    "\n",
    "    signals: list[list]\n",
    "    sentences: list[str]\n",
    "    images: list\n",
    "\n",
    "    size: int\n",
    "\n",
    "    def __init__(self, brush_root, display_stats: bool = False, save_to_file: bool = True):\n",
    "        self.brush_root = brush_root\n",
    "        self.display_stats = display_stats\n",
    "        self.save_to_file = save_to_file\n",
    "\n",
    "        self.signals = []\n",
    "        self.sentences = []\n",
    "        self.images = []\n",
    "\n",
    "        self.load_samples()\n",
    "\n",
    "    #Override\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    #Override\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= self.size:\n",
    "            raise Exception(f\"Invalid index: Dataset of size {self.size} has no item at index {idx}\")\n",
    "        image = self.images[idx]\n",
    "        label = self.signals[idx]\n",
    "        return image, label\n",
    "\n",
    "    def load_samples(self):\n",
    "        \"\"\"This function loads the samples forn disk, creatin the offline image in the process\"\"\"\n",
    "        try:\n",
    "            writer_ids = os.listdir(self.brush_root)\n",
    "            total_writers = len(writer_ids)\n",
    "            if self.display_stats:\n",
    "                print(f\"Loading {total_writers} writers\")\n",
    "        except Exception as e:\n",
    "            print(f\"Impossible to read folder {self.brush_root}\")\n",
    "            raise e\n",
    "            \n",
    "        i = 0\n",
    "        for writer_id in writer_ids:\n",
    "            i+=1\n",
    "            writer_path = os.path.join(self.brush_root, writer_id)\n",
    "            #Each drawin is present in three examplaries: n, n_resample20 and n_resample25\n",
    "            #base dataloader selects default (10ms)\n",
    "            drawing_ids = [name for name in os.listdir(writer_path) if \"_\" not in name and \".npy\" not in name]\n",
    "\n",
    "            if self.display_stats:\n",
    "                print(f\"{i}/{total_writers}: Detected {len(drawing_ids)} drawings\")\n",
    "\n",
    "            for drawing_id in drawing_ids:\n",
    "                signal_path = os.path.join(writer_path, drawing_id)\n",
    "                image_path = os.path.join(writer_path, f\"{drawing_id}.npy\")\n",
    "\n",
    "                sentence, signal, char_label = self.load_signal(signal_path)\n",
    "                self.signals.append(signal)\n",
    "                self.sentences.append(sentence)\n",
    "                \n",
    "                if os.path.isfile(image_path):\n",
    "                    with open(image_path, \"rb\") as f:\n",
    "                        image = np.load(f)\n",
    "                else:\n",
    "                    image = self.create_image(signal)\n",
    "                    if self.save_to_file:\n",
    "                        with open(image_path, \"wb\") as f:\n",
    "                            np.save(f, image)\n",
    "\n",
    "                self.images.append(self.create_image(signal))\n",
    "                \n",
    "\n",
    "        self.size = len(self.images)\n",
    "        if self.display_stats:\n",
    "            print(f\"Loaded {self.size} data points\")\n",
    "    \n",
    "    def load_signal(self, filepath: str) -> tuple[str, list, list]:\n",
    "        \"\"\"Load an online sinal from a filepath\n",
    "        Args\n",
    "        -----\n",
    "            Filepath: The name of the file to load from\n",
    "            \n",
    "        Returns\n",
    "        -----\n",
    "            - str: Written sentence as string\n",
    "            - list: Signal of x, y, penUp\n",
    "            - list: List of one-hot vectors with same length as signal identifying charachter of point\n",
    "        \"\"\"\n",
    "        with open(filepath, 'rb') as f:\n",
    "            [sentence, signal, label] = pickle.load(f)\n",
    "        \n",
    "        return sentence, signal, label\n",
    "    \n",
    "\n",
    "    def create_image(self, signal: list[int, int, bool]):\n",
    "        \"\"\"Create the image associated with the given signal.\"\"\"\n",
    "        max_h =  int(math.ceil(max(signal[:, 0])))\n",
    "        max_w = int(math.ceil(max(signal[:, 1])))\n",
    "\n",
    "        canvas = np.ascontiguousarray(np.full((max_w, max_h), self.DRAW_COLOR_BLACK), dtype=np.uint8)\n",
    "\n",
    "        #Draw lines from point (t-1) to current point (t) IFF the pen was not up. start with penup\n",
    "        #as we start from point 0.\n",
    "        draw_current_stroke = False\n",
    "        for x, y, eos in signal:\n",
    "            x,y = int(x), int(y)\n",
    "            if draw_current_stroke:\n",
    "                cv2.line(canvas, (last_x, last_y), (x, y), self.DRAW_COLOR_WHITE, self.DRAW_COLOR_SIZE) \n",
    "            last_x, last_y, draw_current_stroke = x, y, not eos\n",
    "        \n",
    "        return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_all_imgs():\n",
    "    \n",
    "    brush_root = \"../../data/handwriting/refined_BRUSH/BRUSH\"\n",
    "    writer_ids = os.listdir(brush_root)\n",
    "\n",
    "    for writer_id in writer_ids:\n",
    "        writer_path = os.path.join(brush_root, writer_id)\n",
    "        #Each drawin is present in three examplaries: n, n_resample20 and n_resample25\n",
    "        #base dataloader selects default (10ms)\n",
    "        img_IDs = [name for name in os.listdir(writer_path) if \".npy\" in name]\n",
    "\n",
    "        for img_ID in img_IDs:\n",
    "            full_path = os.path.join(writer_path, img_ID)\n",
    "            print(full_path)\n",
    "            os.remove(full_path) \n",
    "\n",
    "del_all_imgs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 170 writers\n",
      "1/170: Detected 163 drawings\n",
      "2/170: Detected 163 drawings\n",
      "3/170: Detected 162 drawings\n",
      "4/170: Detected 162 drawings\n",
      "5/170: Detected 164 drawings\n",
      "6/170: Detected 160 drawings\n",
      "7/170: Detected 164 drawings\n",
      "8/170: Detected 164 drawings\n",
      "9/170: Detected 162 drawings\n",
      "10/170: Detected 159 drawings\n",
      "11/170: Detected 159 drawings\n",
      "12/170: Detected 155 drawings\n",
      "13/170: Detected 165 drawings\n",
      "14/170: Detected 165 drawings\n",
      "15/170: Detected 164 drawings\n",
      "16/170: Detected 164 drawings\n",
      "17/170: Detected 163 drawings\n",
      "18/170: Detected 163 drawings\n",
      "19/170: Detected 165 drawings\n",
      "20/170: Detected 166 drawings\n",
      "21/170: Detected 164 drawings\n",
      "22/170: Detected 166 drawings\n",
      "23/170: Detected 163 drawings\n",
      "24/170: Detected 162 drawings\n",
      "25/170: Detected 163 drawings\n",
      "26/170: Detected 165 drawings\n",
      "27/170: Detected 165 drawings\n",
      "28/170: Detected 165 drawings\n",
      "29/170: Detected 165 drawings\n",
      "30/170: Detected 165 drawings\n",
      "31/170: Detected 165 drawings\n",
      "32/170: Detected 161 drawings\n",
      "33/170: Detected 165 drawings\n",
      "34/170: Detected 165 drawings\n",
      "35/170: Detected 163 drawings\n",
      "36/170: Detected 165 drawings\n",
      "37/170: Detected 165 drawings\n",
      "38/170: Detected 166 drawings\n",
      "39/170: Detected 163 drawings\n",
      "40/170: Detected 164 drawings\n",
      "41/170: Detected 165 drawings\n",
      "42/170: Detected 163 drawings\n",
      "43/170: Detected 164 drawings\n",
      "44/170: Detected 162 drawings\n",
      "45/170: Detected 164 drawings\n",
      "46/170: Detected 163 drawings\n",
      "47/170: Detected 164 drawings\n",
      "48/170: Detected 162 drawings\n",
      "49/170: Detected 164 drawings\n",
      "50/170: Detected 162 drawings\n",
      "51/170: Detected 164 drawings\n",
      "52/170: Detected 156 drawings\n",
      "53/170: Detected 157 drawings\n",
      "54/170: Detected 165 drawings\n",
      "55/170: Detected 165 drawings\n",
      "56/170: Detected 163 drawings\n",
      "57/170: Detected 166 drawings\n",
      "58/170: Detected 160 drawings\n",
      "59/170: Detected 162 drawings\n",
      "60/170: Detected 164 drawings\n",
      "61/170: Detected 166 drawings\n",
      "62/170: Detected 163 drawings\n",
      "63/170: Detected 163 drawings\n",
      "64/170: Detected 164 drawings\n",
      "65/170: Detected 166 drawings\n",
      "66/170: Detected 163 drawings\n",
      "67/170: Detected 166 drawings\n"
     ]
    }
   ],
   "source": [
    "BRUSH_ROOT = \"../../data/handwriting/refined_BRUSH/BRUSH\"\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "dataset = BrushDataset(brush_root=BRUSH_ROOT, display_stats=True, save_to_file=False)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print(f\"Size of dataset: {dataset.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRUSH_ROOT = \"../../data/handwriting/refined_BRUSH/BRUSH\"\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "dataset = BrushDataset(brush_root=BRUSH_ROOT, display_stats=True, save_to_file=True)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print(f\"Size of dataset: {dataset.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRUSH_ROOT = \"../../data/handwriting/refined_BRUSH/BRUSH\"\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "dataset = BrushDataset(brush_root=BRUSH_ROOT, display_stats=True, save_to_file=False)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print(f\"Size of dataset: {dataset.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results of dataset creation\n",
    "- Building images from signals:\n",
    "- Building and saving images to file:\n",
    "- Loading from gile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = random.randint(0, dataset.size)\n",
    "\n",
    "image, signal = dataset[n]\n",
    "\n",
    "print(f\"Sentence: {dataset.sentences[n]}\")\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
